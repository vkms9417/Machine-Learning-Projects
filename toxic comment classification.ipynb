{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:44:56.019599Z","iopub.execute_input":"2022-08-21T12:44:56.020047Z","iopub.status.idle":"2022-08-21T12:44:56.028192Z","shell.execute_reply.started":"2022-08-21T12:44:56.020014Z","shell.execute_reply":"2022-08-21T12:44:56.027411Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip', encoding=\"ISO-8859-1\")\ntrain_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:44:59.983321Z","iopub.execute_input":"2022-08-21T12:44:59.983722Z","iopub.status.idle":"2022-08-21T12:45:01.947709Z","shell.execute_reply.started":"2022-08-21T12:44:59.983689Z","shell.execute_reply":"2022-08-21T12:45:01.946779Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip', encoding=\"ISO-8859-1\")\nX_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:45:20.154196Z","iopub.execute_input":"2022-08-21T12:45:20.155015Z","iopub.status.idle":"2022-08-21T12:45:21.849079Z","shell.execute_reply.started":"2022-08-21T12:45:20.154974Z","shell.execute_reply":"2022-08-21T12:45:21.847963Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"y_test = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip')\ny_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:45:39.410239Z","iopub.execute_input":"2022-08-21T12:45:39.410812Z","iopub.status.idle":"2022-08-21T12:45:39.687887Z","shell.execute_reply.started":"2022-08-21T12:45:39.410750Z","shell.execute_reply":"2022-08-21T12:45:39.686773Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# sample text to visualize","metadata":{}},{"cell_type":"code","source":"train_df.sample(1)['comment_text'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:46:08.909989Z","iopub.execute_input":"2022-08-21T12:46:08.910409Z","iopub.status.idle":"2022-08-21T12:46:08.929915Z","shell.execute_reply.started":"2022-08-21T12:46:08.910375Z","shell.execute_reply":"2022-08-21T12:46:08.928684Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#remove hyperlinks\n#remove contractions\n#remove punctuation\n#lemmatization","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:46:23.445159Z","iopub.execute_input":"2022-08-21T12:46:23.445676Z","iopub.status.idle":"2022-08-21T12:46:23.450594Z","shell.execute_reply.started":"2022-08-21T12:46:23.445637Z","shell.execute_reply":"2022-08-21T12:46:23.449688Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import nltk","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:46:26.248958Z","iopub.execute_input":"2022-08-21T12:46:26.249882Z","iopub.status.idle":"2022-08-21T12:46:27.462646Z","shell.execute_reply.started":"2022-08-21T12:46:26.249839Z","shell.execute_reply":"2022-08-21T12:46:27.461590Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:46:31.889237Z","iopub.execute_input":"2022-08-21T12:46:31.890334Z","iopub.status.idle":"2022-08-21T12:46:32.212636Z","shell.execute_reply.started":"2022-08-21T12:46:31.890293Z","shell.execute_reply":"2022-08-21T12:46:32.211780Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!pip install contractions","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:46:40.069641Z","iopub.execute_input":"2022-08-21T12:46:40.070593Z","iopub.status.idle":"2022-08-21T12:46:53.458708Z","shell.execute_reply.started":"2022-08-21T12:46:40.070547Z","shell.execute_reply":"2022-08-21T12:46:53.457198Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import contractions\nimport string","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:47:25.849984Z","iopub.execute_input":"2022-08-21T12:47:25.850507Z","iopub.status.idle":"2022-08-21T12:47:25.873233Z","shell.execute_reply.started":"2022-08-21T12:47:25.850461Z","shell.execute_reply":"2022-08-21T12:47:25.872093Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def remove_contractions(sent):\n    # creating an empty list\n    expanded_words = []   \n    for word in sent.split(\" \"):\n      # using contractions.fix to expand the shortened words\n        expanded_words.append(contractions.fix(word)) \n\n    return ' '.join(expanded_words)\n\n\ndef to_lowercase(text):\n    return text.lower()\n\n# Remove website links\ndef remove_links(text):\n    template = re.compile(r'https?://\\S+|www\\.\\S+') \n    text = template.sub(r'', text)\n    return text\n\n# Remove HTML tags\ndef remove_html(text):\n    template = re.compile(r'<[^>]*>') \n    text = template.sub(r'', text)\n    return text\n\n\n# Remove stopwords\ndef remove_stopwords(words, stop_words):\n    return [word for word in words if word not in stop_words]\n\n# Remove none ascii characters\ndef remove_non_ascii(text):\n    template = re.compile(r'[^\\x00-\\x7E]+') \n    text = template.sub(r'', text)\n    return text\n\n# Replace none printable characters\ndef remove_non_printable(text):\n    template = re.compile(r'[\\x00-\\x0F]+') \n    text = template.sub(r' ', text)\n    return text\n\n# Remove special characters\ndef remove_special_chars(text):\n        text = re.sub(\"'s\", '', text)\n        template = re.compile('[\"#$%&\\'()\\*\\+-/:;<=>@\\[\\]\\\\\\\\^_`{|}~]') \n        text = template.sub(r' ', text)\n        return text\n\n# Replace multiple punctuation \ndef replace_multiplt_punc(text):\n        text = re.sub('[.!?]{2,}', '.', text)\n        text = re.sub(',+', ',', text) \n        return text\n\n    # Remove numbers\ndef remove_numbers(text):\n        text = re.sub('\\d+', ' ', text)\n        return text\n\ndef handle_spaces(text):\n    # Remove extra spaces\n    text = re.sub('\\s+', ' ', text)\n    \n    # Remove spaces at the beginning and at the end of string\n    text = text.strip() \n    \n    return text\n\ndef remove_punctuation(text):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\n# def stem_words(words):\n#     \"\"\"Stem words in text\"\"\"\n#     stemmer = PorterStemmer()\n#     return [stemmer.stem(word) for word in words]\n\ndef text2words(text):\n      return word_tokenize(text)\n    \ndef lemmatize_words(words):\n    \"\"\"Lemmatize words in text\"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in words]\n\ndef lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in text\"\"\"\n\n    lemmatizer = WordNetLemmatizer()\n    return ([lemmatizer.lemmatize(word, pos='v') for word in words])\n\ndef remove_pattern(text): \n    # remove hi moron \n    text= re.sub(r'(hi)(.*)\\1', r'\\1', text)\n    # remove duplicate words\n    text= re.sub(r\"\\b(\\w+)(?:\\W+\\1\\b)+\",r'\\1', text,flags=re.IGNORECASE)\n    # remove [User:Cirt]] \n    text= re.sub(r\"\\[.*?\\]\", ' ', text)\n    # remove \\n\\n\n    text= re.sub(r\"\\n\", ' ', text)\n    return text\n\ndef clean_text( text):\n    text = remove_contractions(text)\n    text = remove_pattern(text)\n    text = remove_links(text)\n    text = remove_html(text)\n    text = remove_special_chars(text)\n    text = remove_non_ascii(text)\n    text = remove_non_printable(text)\n    text = remove_numbers(text)\n    text = remove_punctuation(text)\n    text = to_lowercase(text)\n    text = handle_spaces(text)\n    words = text2words(text)\n    words = remove_stopwords(words, stop_words)\n    #words = stem_words(words) #either stem or lemmatize\n    words = lemmatize_words(words)\n    words = lemmatize_verbs(words)\n\n    return ' '.join(words)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:47:40.921205Z","iopub.execute_input":"2022-08-21T12:47:40.921670Z","iopub.status.idle":"2022-08-21T12:47:40.944047Z","shell.execute_reply.started":"2022-08-21T12:47:40.921631Z","shell.execute_reply":"2022-08-21T12:47:40.942642Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df['comment_text'] = train_df['comment_text'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:47:44.370210Z","iopub.execute_input":"2022-08-21T12:47:44.371233Z","iopub.status.idle":"2022-08-21T12:50:31.500503Z","shell.execute_reply.started":"2022-08-21T12:47:44.371191Z","shell.execute_reply":"2022-08-21T12:50:31.499423Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:51:47.090811Z","iopub.execute_input":"2022-08-21T12:51:47.091249Z","iopub.status.idle":"2022-08-21T12:51:47.108476Z","shell.execute_reply.started":"2022-08-21T12:51:47.091217Z","shell.execute_reply":"2022-08-21T12:51:47.107126Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_test['comment_text'] = X_test['comment_text'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:55:00.740526Z","iopub.execute_input":"2022-08-21T12:55:00.741588Z","iopub.status.idle":"2022-08-21T12:56:34.303828Z","shell.execute_reply.started":"2022-08-21T12:55:00.741542Z","shell.execute_reply":"2022-08-21T12:56:34.302647Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# import string\n# string.punctuation","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:56:34.306529Z","iopub.execute_input":"2022-08-21T12:56:34.307025Z","iopub.status.idle":"2022-08-21T12:56:34.313162Z","shell.execute_reply.started":"2022-08-21T12:56:34.306965Z","shell.execute_reply":"2022-08-21T12:56:34.312070Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# def clean_text(text):\n#     cleaned_text = text.translate(str.maketrans('', '', string.punctuation))\n#     return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:56:34.315016Z","iopub.execute_input":"2022-08-21T12:56:34.315581Z","iopub.status.idle":"2022-08-21T12:56:34.322993Z","shell.execute_reply.started":"2022-08-21T12:56:34.315528Z","shell.execute_reply":"2022-08-21T12:56:34.322091Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# train_df['comment_text'] = train_df['comment_text'].apply(clean_text)\n# X_test['comment_text'] = X_test['comment_text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:56:34.324986Z","iopub.execute_input":"2022-08-21T12:56:34.326017Z","iopub.status.idle":"2022-08-21T12:56:34.333319Z","shell.execute_reply.started":"2022-08-21T12:56:34.325982Z","shell.execute_reply":"2022-08-21T12:56:34.332562Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# import re\n# train_df['comment_text'] = train_df['comment_text'].apply(lambda s: re.sub(r'[0-9]+', '', s) )\n# train_df['comment_text'] = train_df['comment_text'].apply(lambda s: re.sub(r'[0-9]+', '', s) )","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:56:34.335150Z","iopub.execute_input":"2022-08-21T12:56:34.335979Z","iopub.status.idle":"2022-08-21T12:56:34.345273Z","shell.execute_reply.started":"2022-08-21T12:56:34.335930Z","shell.execute_reply":"2022-08-21T12:56:34.344509Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\n# We create a tokenizer, configured to only take\n# into account the top-1000 most common words\ntokenizer = Tokenizer(num_words=1000, oov_token='UNK')\n# This builds the word index\ntokenizer.fit_on_texts(train_df['comment_text'])\n\n# This turns strings into lists of integer indices.\nsequences = tokenizer.texts_to_sequences(train_df['comment_text'])\n\n# You could also directly get the one-hot binary representations.\n# Note that other vectorization modes than one-hot encoding are supported!\none_hot_results = tokenizer.texts_to_matrix(train_df['comment_text'], mode='binary')\n#tfidf = tokenizer.texts_to_matrix(train_df['comment_text'], mode='tfidf')\n# This is how you can recover the word index that was computed\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:57:03.394560Z","iopub.execute_input":"2022-08-21T12:57:03.394997Z","iopub.status.idle":"2022-08-21T12:57:29.031584Z","shell.execute_reply.started":"2022-08-21T12:57:03.394964Z","shell.execute_reply":"2022-08-21T12:57:29.030057Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"one_hot_results.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:59:11.851034Z","iopub.execute_input":"2022-08-21T12:59:11.852929Z","iopub.status.idle":"2022-08-21T12:59:11.861137Z","shell.execute_reply.started":"2022-08-21T12:59:11.852865Z","shell.execute_reply":"2022-08-21T12:59:11.859929Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# This turns strings into lists of integer indices.\nsequences_test = tokenizer.texts_to_sequences(X_test['comment_text'])\n\n# You could also directly get the one-hot binary representations.\n# Note that other vectorization modes than one-hot encoding are supported!\none_hot_results_test = tokenizer.texts_to_matrix(X_test['comment_text'], mode='binary')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:59:14.829175Z","iopub.execute_input":"2022-08-21T12:59:14.829657Z","iopub.status.idle":"2022-08-21T12:59:23.883086Z","shell.execute_reply.started":"2022-08-21T12:59:14.829618Z","shell.execute_reply":"2022-08-21T12:59:23.882239Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import models\nfrom tensorflow.keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(1000,)))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(6, activation='sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:59:28.658967Z","iopub.execute_input":"2022-08-21T12:59:28.660059Z","iopub.status.idle":"2022-08-21T12:59:29.224016Z","shell.execute_reply.started":"2022-08-21T12:59:28.660004Z","shell.execute_reply":"2022-08-21T12:59:29.222862Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\nmodel.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:59:37.909791Z","iopub.execute_input":"2022-08-21T12:59:37.910183Z","iopub.status.idle":"2022-08-21T12:59:37.925968Z","shell.execute_reply.started":"2022-08-21T12:59:37.910149Z","shell.execute_reply":"2022-08-21T12:59:37.925005Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"history = model.fit(one_hot_results,\n                    train_df[['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']],\n                    epochs=4,\n                    batch_size=256,\n                    validation_split=0.2)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:59:58.089741Z","iopub.execute_input":"2022-08-21T12:59:58.090187Z","iopub.status.idle":"2022-08-21T13:00:10.293732Z","shell.execute_reply.started":"2022-08-21T12:59:58.090151Z","shell.execute_reply":"2022-08-21T13:00:10.292363Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:00:24.402200Z","iopub.execute_input":"2022-08-21T13:00:24.402617Z","iopub.status.idle":"2022-08-21T13:00:24.410509Z","shell.execute_reply.started":"2022-08-21T13:00:24.402582Z","shell.execute_reply":"2022-08-21T13:00:24.409409Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:00:59.832598Z","iopub.execute_input":"2022-08-21T13:00:59.833066Z","iopub.status.idle":"2022-08-21T13:01:00.103422Z","shell.execute_reply.started":"2022-08-21T13:00:59.833027Z","shell.execute_reply":"2022-08-21T13:01:00.102280Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"plt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['accuracy']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:01:59.452525Z","iopub.execute_input":"2022-08-21T13:01:59.452992Z","iopub.status.idle":"2022-08-21T13:01:59.684560Z","shell.execute_reply.started":"2022-08-21T13:01:59.452944Z","shell.execute_reply":"2022-08-21T13:01:59.683424Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\ny_pred = model.predict(one_hot_results_test)\ny_pred = pd.DataFrame(y_pred)#.applymap(lambda x: 1 if x>0.5 else 0)\ny_pred.columns = ['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']\nsubmit[['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']] = y_pred\nsubmit.to_csv('submit_file.csv', index=None)\n#Score: 0.91","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:03:02.922249Z","iopub.execute_input":"2022-08-21T13:03:02.922747Z","iopub.status.idle":"2022-08-21T13:03:12.713016Z","shell.execute_reply.started":"2022-08-21T13:03:02.922703Z","shell.execute_reply":"2022-08-21T13:03:12.711918Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:04:25.753674Z","iopub.execute_input":"2022-08-21T13:04:25.754330Z","iopub.status.idle":"2022-08-21T13:04:25.762714Z","shell.execute_reply.started":"2022-08-21T13:04:25.754293Z","shell.execute_reply":"2022-08-21T13:04:25.761259Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nlengths = [len(sequence) for sequence in sequences]\nmax_length = max(lengths)\nsequences_pad = pad_sequences(sequences, maxlen=50)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:04:57.244787Z","iopub.execute_input":"2022-08-21T13:04:57.245225Z","iopub.status.idle":"2022-08-21T13:04:57.812726Z","shell.execute_reply.started":"2022-08-21T13:04:57.245190Z","shell.execute_reply":"2022-08-21T13:04:57.811613Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"mean_lengths = np.mean(lengths)\nmean_lengths","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:05:05.953141Z","iopub.execute_input":"2022-08-21T13:05:05.953568Z","iopub.status.idle":"2022-08-21T13:05:05.972139Z","shell.execute_reply.started":"2022-08-21T13:05:05.953533Z","shell.execute_reply":"2022-08-21T13:05:05.971208Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(lengths, bins=100);\nplt.xlim([min(lengths), max(lengths)-1000]);","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:05:08.547926Z","iopub.execute_input":"2022-08-21T13:05:08.548654Z","iopub.status.idle":"2022-08-21T13:05:09.417798Z","shell.execute_reply.started":"2022-08-21T13:05:08.548612Z","shell.execute_reply":"2022-08-21T13:05:09.416702Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"seq_length = sequences_pad.shape[1]\nseq_length","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:05:11.912734Z","iopub.execute_input":"2022-08-21T13:05:11.913569Z","iopub.status.idle":"2022-08-21T13:05:11.920143Z","shell.execute_reply.started":"2022-08-21T13:05:11.913523Z","shell.execute_reply":"2022-08-21T13:05:11.919314Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"max_length = 40","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:05:14.512666Z","iopub.execute_input":"2022-08-21T13:05:14.513078Z","iopub.status.idle":"2022-08-21T13:05:14.518532Z","shell.execute_reply.started":"2022-08-21T13:05:14.513043Z","shell.execute_reply":"2022-08-21T13:05:14.517527Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Embedding(vocab_size, 50, input_length=max_length))\nmodel.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\nmodel.add(layers.LSTM(64,dropout=0.2, recurrent_dropout=0.2,))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(6, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:05:17.327436Z","iopub.execute_input":"2022-08-21T13:05:17.328433Z","iopub.status.idle":"2022-08-21T13:05:17.643261Z","shell.execute_reply.started":"2022-08-21T13:05:17.328392Z","shell.execute_reply":"2022-08-21T13:05:17.642321Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(sequences_pad,\n                    train_df[['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']],\n                    epochs=4,\n                    batch_size=256,\n                    validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:05:28.893448Z","iopub.execute_input":"2022-08-21T13:05:28.893842Z","iopub.status.idle":"2022-08-21T13:30:43.137503Z","shell.execute_reply.started":"2022-08-21T13:05:28.893801Z","shell.execute_reply":"2022-08-21T13:30:43.136193Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:31:37.711576Z","iopub.execute_input":"2022-08-21T13:31:37.711988Z","iopub.status.idle":"2022-08-21T13:31:37.936411Z","shell.execute_reply.started":"2022-08-21T13:31:37.711956Z","shell.execute_reply":"2022-08-21T13:31:37.935569Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"plt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['accuracy']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:31:47.572551Z","iopub.execute_input":"2022-08-21T13:31:47.573894Z","iopub.status.idle":"2022-08-21T13:31:47.807697Z","shell.execute_reply.started":"2022-08-21T13:31:47.573839Z","shell.execute_reply":"2022-08-21T13:31:47.806421Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:32:03.102113Z","iopub.execute_input":"2022-08-21T13:32:03.102519Z","iopub.status.idle":"2022-08-21T13:32:03.337471Z","shell.execute_reply.started":"2022-08-21T13:32:03.102485Z","shell.execute_reply":"2022-08-21T13:32:03.336383Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"sequences_test_pad =  pad_sequences(sequences_test, maxlen=max_length)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:32:23.831684Z","iopub.execute_input":"2022-08-21T13:32:23.832125Z","iopub.status.idle":"2022-08-21T13:32:24.404326Z","shell.execute_reply.started":"2022-08-21T13:32:23.832088Z","shell.execute_reply":"2022-08-21T13:32:24.402950Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(sequences_test_pad)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:38:09.002319Z","iopub.execute_input":"2022-08-21T13:38:09.002788Z","iopub.status.idle":"2022-08-21T13:38:55.309946Z","shell.execute_reply.started":"2022-08-21T13:38:09.002752Z","shell.execute_reply":"2022-08-21T13:38:55.307968Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:39:34.812032Z","iopub.execute_input":"2022-08-21T13:39:34.812529Z","iopub.status.idle":"2022-08-21T13:39:34.832960Z","shell.execute_reply.started":"2022-08-21T13:39:34.812481Z","shell.execute_reply":"2022-08-21T13:39:34.831855Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.DataFrame(y_pred)#.applymap(lambda x: 1 if x>0.5 else 0)\ny_pred.columns = ['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:41:12.480049Z","iopub.execute_input":"2022-08-21T13:41:12.480524Z","iopub.status.idle":"2022-08-21T13:41:12.486987Z","shell.execute_reply.started":"2022-08-21T13:41:12.480490Z","shell.execute_reply":"2022-08-21T13:41:12.485755Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"submit[['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']] = y_pred","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:41:16.021145Z","iopub.execute_input":"2022-08-21T13:41:16.021578Z","iopub.status.idle":"2022-08-21T13:41:16.033394Z","shell.execute_reply.started":"2022-08-21T13:41:16.021542Z","shell.execute_reply":"2022-08-21T13:41:16.031907Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submit_lstm.csv', index=None)#Score: 0.65039","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:39:08.651082Z","iopub.execute_input":"2022-08-21T13:39:08.651508Z","iopub.status.idle":"2022-08-21T13:39:09.767490Z","shell.execute_reply.started":"2022-08-21T13:39:08.651472Z","shell.execute_reply":"2022-08-21T13:39:09.766505Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Bidirectional GRU","metadata":{}},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Embedding(vocab_size, 100, input_length=seq_length))\nmodel.add(layers.Bidirectional(layers.GRU(256, return_sequences=True)))\nmodel.add(layers.Bidirectional(layers.GRU(128)))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(6, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:41:23.771497Z","iopub.execute_input":"2022-08-21T13:41:23.772310Z","iopub.status.idle":"2022-08-21T13:41:24.697570Z","shell.execute_reply.started":"2022-08-21T13:41:23.772266Z","shell.execute_reply":"2022-08-21T13:41:24.696530Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizers.RMSprop(learning_rate=0.01),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(sequences_pad,\n                    train_df[['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']],\n                    epochs=5,\n                    batch_size=256,\n                    validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:41:28.350918Z","iopub.execute_input":"2022-08-21T13:41:28.351322Z","iopub.status.idle":"2022-08-21T14:41:04.243477Z","shell.execute_reply.started":"2022-08-21T13:41:28.351289Z","shell.execute_reply":"2022-08-21T14:41:04.242493Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T14:42:24.038067Z","iopub.execute_input":"2022-08-21T14:42:24.039178Z","iopub.status.idle":"2022-08-21T14:42:24.271742Z","shell.execute_reply.started":"2022-08-21T14:42:24.039117Z","shell.execute_reply":"2022-08-21T14:42:24.270473Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"plt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['accuracy']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T14:42:29.173664Z","iopub.execute_input":"2022-08-21T14:42:29.174098Z","iopub.status.idle":"2022-08-21T14:42:29.415958Z","shell.execute_reply.started":"2022-08-21T14:42:29.174062Z","shell.execute_reply":"2022-08-21T14:42:29.414765Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"sequences_test_pad =  pad_sequences(sequences_test, maxlen=max_length)\ny_pred = model.predict(sequences_test_pad)\ny_pred = pd.DataFrame(y_pred)#.applymap(lambda x: 1 if x>0.5 else 0)\ny_pred.columns = ['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']\nsubmit[['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']] = y_pred\nsubmit.to_csv('submit_gru.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T14:42:35.668219Z","iopub.execute_input":"2022-08-21T14:42:35.668641Z","iopub.status.idle":"2022-08-21T14:49:34.679726Z","shell.execute_reply.started":"2022-08-21T14:42:35.668607Z","shell.execute_reply":"2022-08-21T14:49:34.678329Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2022-08-21T14:49:34.681805Z","iopub.execute_input":"2022-08-21T14:49:34.682175Z","iopub.status.idle":"2022-08-21T14:49:34.701251Z","shell.execute_reply.started":"2022-08-21T14:49:34.682140Z","shell.execute_reply":"2022-08-21T14:49:34.699750Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}